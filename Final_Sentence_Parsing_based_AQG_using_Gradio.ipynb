{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pJuvDJ2af2I8",
        "QA0x054Dsgoa"
      ],
      "authorship_tag": "ABX9TyOH4pPa4BUjJfDYZlNcBVto",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleligntewabe/Automatic-Question-Generation/blob/main/Final_Sentence_Parsing_based_AQG_using_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a function to analyze the sentence\n",
        "def analyze_sentence(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    nsubj, dobj, pobj, prep, npadvmod, advmod,s = [],[], [], [], [], [], []\n",
        "\n",
        "    adverb_types = {\n",
        "    \"Degree\": [\"Somewhat\", \"Enormously\", \"Totally\", \"Utterly\", \"Perfectly\", \"Absolutely\", \"Practically\", \"Barely\",\n",
        "               \"Terribly\", \"Pretty\", \"Thoroughly\", \"Rather\", \"Extremely\", \"Incredibly\", \"Most\", \"Purely\", \"Little\",\n",
        "               \"Virtually\", \"Very\", \"Fully\", \"Indeed\", \"Hardly\", \"Almost\", \"Strongly\", \"So\", \"Less\", \"Fairly\",\n",
        "               \"Greatly\", \"Entirely\", \"Highly\", \"Lots\", \"Really\", \"Quite\", \"Too\", \"Completely\", \"Well\", \"Far\",\n",
        "               \"Deeply\", \"Badly\", \"Scarcely\", \"Positively\", \"How\", \"Enough\", \"Awfully\"],\n",
        "    \"Manner\": [\"Promptly\", \"Powerfully\", \"Calmly\", \"Politely\", \"Equally\", \"Faithfully\", \"Generously\", \"Gladly\",\n",
        "               \"Joyously\", \"Easily\", \"Beautifully\", \"Kindly\", \"Bravely\", \"Poorly\", \"Shyly\", \"Foolishly\", \"Selfishly\",\n",
        "               \"Angrily\", \"Awkwardly\", \"Violently\", \"Suspiciously\", \"Inadequately\", \"Irritably\", \"Hungrily\",\n",
        "               \"Generally\", \"Frequently\", \"Noisily\"],\n",
        "    \"Place\": [\"Behind\", \"About\", \"Upstairs\", \"Up\", \"Out\", \"Far\", \"Inside\", \"Right\", \"There\", \"Backward/s\", \"Nearby\",\n",
        "              \"On\", \"Away\", \"Back\", \"Indoors\", \"Overseas\", \"Abroad\", \"Down\", \"Over\", \"Towards\", \"Here\", \"Anywhere\",\n",
        "              \"Underground\", \"Elsewhere\", \"Off\", \"Regularly\", \"Previously\", \"Seldom\", \"Now\", \"Since\", \"Finally\",\n",
        "              \"Tomorrow\", \"Everywhere\"],\n",
        "    \"Time\": [\"Today\", \"Tonigh\", \"Occasionally\", \"Constantly\", \"Rarely\", \"Quarterly\", \"Weekly\", \"yesterday\", \"Later\",\n",
        "             \"Then\", \"Eventually\", \"Suddenly\", \"Mysteriously\", \"Infrequently\", \"Continually\", \"Yearly\", \"Monthly\",\n",
        "             \"Fortnightly\", \"First\", \"Annually\", \"Yearly\", \"Tonight\", \"Tomorrow\", \"Recently\", \"Late\", \"Accidentally\",\n",
        "             \"Seriouly\", \"Deliberately\", \"Never\", \"Seriously\"],\n",
        "    \"Frequency\": [\"Exactly\", \"Intermittently\", \"Quarterly\", \"Weekly\", \"Solemnly\"]\n",
        "    }\n",
        "\n",
        "    for token in doc:\n",
        "        s.append(token.text)\n",
        "        if token.dep_ == 'nsubj':\n",
        "            nsubj = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Subject type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ == 'ROOT':\n",
        "            dobj = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Verb type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ in ['pobj', 'dobj', 'acomp']:\n",
        "            pobj = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Object type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ == 'prep':\n",
        "            prep = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Preposition type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ == 'npadvmod':\n",
        "            npadvmod = s\n",
        "            s = []\n",
        "\n",
        "        if token.dep_ == 'advmod':\n",
        "            advmod = s\n",
        "            s = []\n",
        "        # ... (implement other conditions similarly)\n",
        "\n",
        "        # Categorize adverbs (keep this logic as it is)\n",
        "        # Categorize adverbs based on adverb type dataset\n",
        "    adverb_type_category = \"\"\n",
        "    for adverb in advmod or npadvmod:\n",
        "        adverb = re.sub(\"[']\", \"\", adverb)\n",
        "        adverb = re.sub(\"[,]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[[]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[]]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[)]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[(]\", \"\", adverb)\n",
        "        #print(\"adverb=\",adverb)\n",
        "        if adverb in adverb_types[\"Degree\"]:\n",
        "            adverb_type_category = \"Degree\"\n",
        "            degree_adverb=adverb\n",
        "        elif adverb in adverb_types[\"Manner\"]:\n",
        "            adverb_type_category = \"Manner\"\n",
        "            manner_adverb=adverb\n",
        "        elif adverb in adverb_types[\"Place\"]:\n",
        "            adverb_type_category = \"Place\"\n",
        "            place_adverb=adverb\n",
        "        elif adverb in adverb_types[\"Time\"]:\n",
        "            adverb_type_category = \"Time\"\n",
        "            #print(\"time_adverb=\",adverb)\n",
        "            time_adverb=adverb\n",
        "        elif adverb in adverb_types[\"Frequency\"]:\n",
        "            adverb_type_category = \"Frequency\"\n",
        "            frequency_adverb=adverb\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Subject=\", nsubj)\n",
        "    print(\"Verb=\", dobj)\n",
        "    print(\"Object=\", pobj)\n",
        "    #print(\"Preposition=\", prep)\n",
        "    print(\"Time Adverb=\", time_adverb)\n",
        "    #print(\"Place Adverb=\", place_adverb)\n",
        "    #print(\"Degree Adverb=\", degree_adverb)\n",
        "    #print(\"Frequency Adverb=\", frequency_adverb)\n",
        "    #print(\"Manner Adverb=\", manner_adverb)\n",
        "    return (nsubj,dobj,pobj,time_adverb)"
      ],
      "metadata": {
        "id": "WJUsvRxondXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "AxvS0YgE4KZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load the Spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to analyze a sentence and extract its components\n",
        "def analyze_sentence(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        'nsubj': [], 'verb': [], 'obj': [], 'prep': [], 'time_adverb': [], 'advmod':[],'npadvmod':[],\n",
        "        'place_adverb': [], 'degree_adverb': [],  'manner_adverb': [], 'frequency_adverb': []\n",
        "    }\n",
        "\n",
        "    adverb_types = {\n",
        "      \"Degree\": [\"Somewhat\", \"Enormously\", \"Totally\", \"Utterly\", \"Perfectly\", \"Absolutely\", \"Practically\", \"Barely\",\n",
        "                \"Terribly\", \"Pretty\", \"Thoroughly\", \"Rather\", \"Extremely\", \"Incredibly\", \"Most\", \"Purely\", \"Little\",\n",
        "                \"Virtually\", \"Very\", \"Fully\", \"Indeed\", \"Hardly\", \"Almost\", \"Strongly\", \"So\", \"Less\", \"Fairly\",\n",
        "                \"Greatly\", \"Entirely\", \"Highly\", \"Lots\", \"Really\", \"Quite\", \"Too\", \"Completely\", \"Well\", \"Far\",\n",
        "                \"Deeply\", \"Badly\", \"Scarcely\", \"Positively\", \"How\", \"Enough\", \"Awfully\"],\n",
        "      \"Manner\": [\"Promptly\", \"Powerfully\", \"Calmly\", \"Politely\", \"Equally\", \"Faithfully\", \"Generously\", \"Gladly\",\n",
        "                \"Joyously\", \"Easily\", \"Beautifully\", \"Kindly\", \"Bravely\", \"Poorly\", \"Shyly\", \"Foolishly\", \"Selfishly\",\n",
        "                \"Angrily\", \"Awkwardly\", \"Violently\", \"Suspiciously\", \"Inadequately\", \"Irritably\", \"Hungrily\",\n",
        "                \"Generally\", \"Frequently\", \"Noisily\"],\n",
        "      \"Place\": [\"Behind\", \"About\", \"Upstairs\", \"Up\", \"Out\", \"Far\", \"Inside\", \"Right\", \"There\", \"Backward/s\", \"Nearby\",\n",
        "                \"On\", \"Away\", \"Back\", \"Indoors\", \"Overseas\", \"Abroad\", \"Down\", \"Over\", \"Towards\", \"Here\", \"Anywhere\",\n",
        "                \"Underground\", \"Elsewhere\", \"Off\", \"Regularly\", \"Previously\", \"Seldom\", \"Now\", \"Since\", \"Finally\",\n",
        "                \"Tomorrow\", \"Everywhere\"],\n",
        "      \"Time\": [\"Today\", \"Tonigh\", \"Occasionally\", \"Constantly\", \"Rarely\", \"Quarterly\", \"Weekly\", \"yesterday\", \"Later\",\n",
        "              \"Then\", \"Eventually\", \"Suddenly\", \"Mysteriously\", \"Infrequently\", \"Continually\", \"Yearly\", \"Monthly\",\n",
        "              \"Fortnightly\", \"First\", \"Annually\", \"Yearly\", \"Tonight\", \"Tomorrow\", \"Recently\", \"Late\", \"Accidentally\",\n",
        "              \"Seriouly\", \"Deliberately\", \"Never\", \"Seriously\"],\n",
        "      \"Frequency\": [\"Exactly\", \"Intermittently\", \"Quarterly\", \"Weekly\", \"Solemnly\"]\n",
        "      }\n",
        "# Extract components\n",
        "    for token in doc:\n",
        "\n",
        "        if token.dep_ == 'nsubj':\n",
        "            components['nsubj'].append(token.text)\n",
        "        if token.dep_ == 'ROOT':\n",
        "            components['verb'].append(token.text)\n",
        "        if token.dep_ in ['pobj', 'dobj', 'acomp']:\n",
        "            components['obj'].append(token.text)\n",
        "        if token.dep_ == 'prep':\n",
        "            components['prep'].append(token.text)\n",
        "\n",
        "        if token.dep_ == 'npadvmod' or 'advmod':\n",
        "            adverb = token.text\n",
        "\n",
        "            if adverb in adverb_types[\"Degree\"]:\n",
        "                adverb_type_category = \"Degree\"\n",
        "                degree_adverb=adverb\n",
        "                components['degree_adverb'].append(token.text)\n",
        "            elif adverb in adverb_types[\"Manner\"]:\n",
        "                adverb_type_category = \"Manner\"\n",
        "                manner_adverb=adverb\n",
        "                components['manner_adverb'].append(token.text)\n",
        "            elif adverb in adverb_types[\"Place\"]:\n",
        "                adverb_type_category = \"Place\"\n",
        "                place_adverb=adverb\n",
        "                components['place_adverb'].append(token.text)\n",
        "            elif adverb in adverb_types[\"Time\"]:\n",
        "                adverb_type_category = \"Time\"\n",
        "                print(\"time_adverb=\",adverb)\n",
        "                time_adverb=adverb\n",
        "                components['time_adverb'].append(token.text)\n",
        "                print(\"Time=\",components['time_adverb'])\n",
        "            elif adverb in adverb_types[\"Frequency\"]:\n",
        "                adverb_type_category = \"Frequency\"\n",
        "                frequency_adverb=adverb\n",
        "                components['frequency_adverb'].append(token.text)\n",
        "\n",
        "    return components\n",
        "\n",
        "# Function to generate questions\n",
        "def generate_questions(subject, verb, obj, prep, time_adverb):\n",
        "    questions = []\n",
        "\n",
        "    # Generate Wh-questions\n",
        "    if subject:\n",
        "        questions.append(f\"Who {verb} {obj} {prep} {time_adverb}?\")\n",
        "\n",
        "    if obj:\n",
        "        questions.append(f\"What did {subject} {verb} {prep} {time_adverb}?\")\n",
        "\n",
        "    if time_adverb:\n",
        "        questions.append(f\"When did {subject} {verb} {obj} {prep}?\")\n",
        "\n",
        "    # Generate Yes/No questions\n",
        "    if subject and verb and obj:\n",
        "        questions.append(f\"Did {subject} {verb} {obj}?\")\n",
        "\n",
        "    return questions\n",
        "\n",
        "# Function to generate and display questions\n",
        "def display_questions(components):\n",
        "    questions = generate_questions(\n",
        "        subject=components['nsubj'],\n",
        "        verb=components['verb'],\n",
        "        obj=components['obj'],\n",
        "        prep=components['prep'],\n",
        "        time_adverb=components['time_adverb']\n",
        "    )\n",
        "        #place_adverb=components['place_adverb'],\n",
        "        #degree_adverb=components['degree_adverb'],\n",
        "        #manner_adverb=components['manner_adverb'],\n",
        "        #frequency_adverb=components['frequency_adverb']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BmpeF80At3fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Old Modified function to work with Gradio\n",
        "def display_questions_with_gradio(sentence):\n",
        "    components = analyze_sentence(sentence)\n",
        "    print(components)\n",
        "    questions=display_questions(components)\n",
        "    print(questions)\n",
        "    # Generating questions\n",
        "\n",
        "    # Generating questions\n",
        "    #questions = generate_questions(subject, verb, obj, prep, time_adverb, place_adverb,degree_adverb, manner_adverb, frequency_adverb)\n",
        "\n",
        "\n",
        "    # Format the questions for display\n",
        "    #formatted_questions = \"\\n\".join([f\"Question {i}: {q}\" for i, q in enumerate(questions, 1)])\n",
        "    #return formatted_questions\n",
        "\n",
        "    # Displaying generated questions\n",
        "    for i, question in enumerate(questions, 1):\n",
        "        question = re.sub(\"[']\", \"\", question)\n",
        "        question = re.sub(\"[,]\", \"\", question)\n",
        "        question = re.sub(\"[[]\", \"\", question)\n",
        "        question = re.sub(\"[]]\", \"\", question)\n",
        "        question = re.sub(\"[)]\", \"\", question)\n",
        "        question = re.sub(\"[(]\", \"\", question)\n",
        "        #print(f\"Question {i}: {question}\")\n",
        "        formatted_questions = \"\\n\".join([f\"Question {i}: {question}\"])\n",
        "    return formatted_questions"
      ],
      "metadata": {
        "id": "1q7walATYWXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#New\n",
        "def display_questions_with_gradio(sentence):\n",
        "    components = analyze_sentence(sentence)\n",
        "    questions = generate_questions(\n",
        "        components['nsubj'],\n",
        "        components['verb'],\n",
        "        components['obj'],\n",
        "        components['prep'],\n",
        "        components['time_adverb']\n",
        "    )\n",
        "\n",
        "    # Check if questions list is not None and not empty\n",
        "    if questions:\n",
        "        formatted_questions = \"\\n\".join([f\"Question {i}: {q}\" for i, q in enumerate(questions, 1)])\n",
        "\n",
        "        formatted_questions = re.sub(\"[']\", \"\", formatted_questions)\n",
        "        formatted_questions = re.sub(\"[,]\", \"\", formatted_questions)\n",
        "        formatted_questions = re.sub(\"[[]\", \"\", formatted_questions)\n",
        "        formatted_questions = re.sub(\"[]]\", \"\", formatted_questions)\n",
        "        formatted_questions = re.sub(\"[)]\", \"\", formatted_questions)\n",
        "        formatted_questions = re.sub(\"[(]\", \"\", formatted_questions)\n",
        "\n",
        "    else:\n",
        "        formatted_questions = \"No questions generated.\"\n",
        "\n",
        "    return formatted_questions\n"
      ],
      "metadata": {
        "id": "lMklW15HYUBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_sentence(\"John ate an apple yesterday\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_eL2il9Ufki",
        "outputId": "88af75b3-a48e-4bb5-ab5d-261684bb496c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time_adverb= yesterday\n",
            "Time= ['yesterday']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nsubj': ['John'],\n",
              " 'verb': ['ate'],\n",
              " 'obj': ['apple'],\n",
              " 'prep': [],\n",
              " 'time_adverb': ['yesterday'],\n",
              " 'advmod': [],\n",
              " 'npadvmod': [],\n",
              " 'place_adverb': [],\n",
              " 'degree_adverb': [],\n",
              " 'manner_adverb': [],\n",
              " 'frequency_adverb': []}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_questions_with_gradio(\"John ate an apple yesterday\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "ffrHGF6qQLDJ",
        "outputId": "b63e9cb0-7354-4999-c2b2-eacdc45b6ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time_adverb= yesterday\n",
            "Time= ['yesterday']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question 1: Who ate apple  yesterday?\\nQuestion 2: What did John ate  yesterday?\\nQuestion 3: When did John ate apple ?\\nQuestion 4: Did John ate apple?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=display_questions_with_gradio,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "W-wROxckQFOx",
        "outputId": "bef01ef0-92d2-495c-8f16-e1556583c6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0819d303c9bbb2d1ab.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0819d303c9bbb2d1ab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Other**"
      ],
      "metadata": {
        "id": "m7LmZEM_nayO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb3Eb_Fup8yE",
        "outputId": "85884e2f-eb7a-458f-aabd-41fcb4d5d652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject type= PERSON John\n",
            "Object type= ORG apple\n",
            "Subject= ['John']\n",
            "Verb= ['ate']\n",
            "Object= ['an', 'apple']\n",
            "Time Adverb= yesterday\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp('John ate an apple yesterday')\n",
        "\n",
        "s = []\n",
        "nsubj = []\n",
        "dobj = []\n",
        "pobj = []\n",
        "prep = []\n",
        "advmod=[]\n",
        "npadvmod=[]\n",
        "time_adverb = []\n",
        "place_adverb = []\n",
        "manner_adverb = []\n",
        "degree_adverb = []\n",
        "frequency_adverb = []\n",
        "\n",
        "adverb_types = {\n",
        "    \"Degree\": [\"Somewhat\", \"Enormously\", \"Totally\", \"Utterly\", \"Perfectly\", \"Absolutely\", \"Practically\", \"Barely\",\n",
        "               \"Terribly\", \"Pretty\", \"Thoroughly\", \"Rather\", \"Extremely\", \"Incredibly\", \"Most\", \"Purely\", \"Little\",\n",
        "               \"Virtually\", \"Very\", \"Fully\", \"Indeed\", \"Hardly\", \"Almost\", \"Strongly\", \"So\", \"Less\", \"Fairly\",\n",
        "               \"Greatly\", \"Entirely\", \"Highly\", \"Lots\", \"Really\", \"Quite\", \"Too\", \"Completely\", \"Well\", \"Far\",\n",
        "               \"Deeply\", \"Badly\", \"Scarcely\", \"Positively\", \"How\", \"Enough\", \"Awfully\"],\n",
        "    \"Manner\": [\"Promptly\", \"Powerfully\", \"Calmly\", \"Politely\", \"Equally\", \"Faithfully\", \"Generously\", \"Gladly\",\n",
        "               \"Joyously\", \"Easily\", \"Beautifully\", \"Kindly\", \"Bravely\", \"Poorly\", \"Shyly\", \"Foolishly\", \"Selfishly\",\n",
        "               \"Angrily\", \"Awkwardly\", \"Violently\", \"Suspiciously\", \"Inadequately\", \"Irritably\", \"Hungrily\",\n",
        "               \"Generally\", \"Frequently\", \"Noisily\"],\n",
        "    \"Place\": [\"Behind\", \"About\", \"Upstairs\", \"Up\", \"Out\", \"Far\", \"Inside\", \"Right\", \"There\", \"Backward/s\", \"Nearby\",\n",
        "              \"On\", \"Away\", \"Back\", \"Indoors\", \"Overseas\", \"Abroad\", \"Down\", \"Over\", \"Towards\", \"Here\", \"Anywhere\",\n",
        "              \"Underground\", \"Elsewhere\", \"Off\", \"Regularly\", \"Previously\", \"Seldom\", \"Now\", \"Since\", \"Finally\",\n",
        "              \"Tomorrow\", \"Everywhere\"],\n",
        "    \"Time\": [\"Today\", \"Tonigh\", \"Occasionally\", \"Constantly\", \"Rarely\", \"Quarterly\", \"Weekly\", \"yesterday\", \"Later\",\n",
        "             \"Then\", \"Eventually\", \"Suddenly\", \"Mysteriously\", \"Infrequently\", \"Continually\", \"Yearly\", \"Monthly\",\n",
        "             \"Fortnightly\", \"First\", \"Annually\", \"Yearly\", \"Tonight\", \"Tomorrow\", \"Recently\", \"Late\", \"Accidentally\",\n",
        "             \"Seriouly\", \"Deliberately\", \"Never\", \"Seriously\"],\n",
        "    \"Frequency\": [\"Exactly\", \"Intermittently\", \"Quarterly\", \"Weekly\", \"Solemnly\"]\n",
        "}\n",
        "\n",
        "for token in doc:\n",
        "    s.append(token.text)\n",
        "    if token.dep_ == 'nsubj':\n",
        "        nsubj = s\n",
        "        s = []\n",
        "        subjNer = nlp(token.text)\n",
        "        for ent in subjNer.ents:\n",
        "            print(\"Subject type=\", ent.label_, ent.text)\n",
        "\n",
        "    if token.dep_ == 'ROOT':\n",
        "        dobj = s\n",
        "        s = []\n",
        "        subjNer = nlp(token.text)\n",
        "        for ent in subjNer.ents:\n",
        "            print(\"Verb type=\", ent.label_, ent.text)\n",
        "\n",
        "    if token.dep_ in ['pobj', 'dobj', 'acomp']:\n",
        "        pobj = s\n",
        "        s = []\n",
        "        subjNer = nlp(token.text)\n",
        "        for ent in subjNer.ents:\n",
        "            print(\"Object type=\", ent.label_, ent.text)\n",
        "\n",
        "    if token.dep_ == 'prep':\n",
        "        prep = s\n",
        "        s = []\n",
        "        subjNer = nlp(token.text)\n",
        "        for ent in subjNer.ents:\n",
        "            print(\"Preposition type=\", ent.label_, ent.text)\n",
        "\n",
        "    if token.dep_ == 'npadvmod':\n",
        "        npadvmod = s\n",
        "        s = []\n",
        "\n",
        "    if token.dep_ == 'advmod':\n",
        "        advmod = s\n",
        "        s = []\n",
        "\n",
        "# Categorize adverbs based on adverb type dataset\n",
        "adverb_type_category = \"\"\n",
        "for adverb in advmod or npadvmod:\n",
        "    adverb = re.sub(\"[']\", \"\", adverb)\n",
        "    adverb = re.sub(\"[,]\", \"\", adverb)\n",
        "    adverb = re.sub(\"[[]\", \"\", adverb)\n",
        "    adverb = re.sub(\"[]]\", \"\", adverb)\n",
        "    adverb = re.sub(\"[)]\", \"\", adverb)\n",
        "    adverb = re.sub(\"[(]\", \"\", adverb)\n",
        "    #print(\"adverb=\",adverb)\n",
        "    if adverb in adverb_types[\"Degree\"]:\n",
        "        adverb_type_category = \"Degree\"\n",
        "        degree_adverb=adverb\n",
        "    elif adverb in adverb_types[\"Manner\"]:\n",
        "        adverb_type_category = \"Manner\"\n",
        "        manner_adverb=adverb\n",
        "    elif adverb in adverb_types[\"Place\"]:\n",
        "        adverb_type_category = \"Place\"\n",
        "        place_adverb=adverb\n",
        "    elif adverb in adverb_types[\"Time\"]:\n",
        "        adverb_type_category = \"Time\"\n",
        "        #print(\"time_adverb=\",adverb)\n",
        "        time_adverb=adverb\n",
        "    elif adverb in adverb_types[\"Frequency\"]:\n",
        "        adverb_type_category = \"Frequency\"\n",
        "        frequency_adverb=adverb\n",
        "\n",
        "# Print the results\n",
        "print(\"Subject=\", nsubj)\n",
        "print(\"Verb=\", dobj)\n",
        "print(\"Object=\", pobj)\n",
        "#print(\"Preposition=\", prep)\n",
        "print(\"Time Adverb=\", time_adverb)\n",
        "#print(\"Place Adverb=\", place_adverb)\n",
        "#print(\"Degree Adverb=\", degree_adverb)\n",
        "#print(\"Frequency Adverb=\", frequency_adverb)\n",
        "#print(\"Manner Adverb=\", manner_adverb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatic Question Generation based on Extracted Information\n",
        "\n",
        "# Function to generate questions\n",
        "def generate_questions1(subject, verb, obj, prep, time_adverb, place_adverb, degree_adverb, manner_adverb, frequency_adverb):\n",
        "    questions = []\n",
        "\n",
        "    # Generate Wh-questions\n",
        "    if subject:\n",
        "        questions.append(f\"Who {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "    if obj:\n",
        "        questions.append(f\"What did {subject} {verb} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "    if time_adverb:\n",
        "        questions.append(f\"When did {subject} {verb} {obj} {prep} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "    if place_adverb:\n",
        "        questions.append(f\"Where did {subject} {verb} {obj} {prep} {time_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "    if degree_adverb:\n",
        "        questions.append(f\"How {degree_adverb} did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "    if manner_adverb:\n",
        "        questions.append(f\"How did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {frequency_adverb}?\")\n",
        "\n",
        "    if frequency_adverb:\n",
        "        questions.append(f\"How often did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb}?\")\n",
        "\n",
        "    # Generate Yes/No questions\n",
        "    if subject and verb and obj:\n",
        "        questions.append(f\"Did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "    return questions\n",
        "\n",
        "# Using extracted information\n",
        "subject = nsubj\n",
        "verb = dobj\n",
        "obj = pobj\n",
        "prep = prep\n",
        "time_adverb = time_adverb\n",
        "place_adverb = place_adverb\n",
        "degree_adverb = degree_adverb\n",
        "manner_adverb = manner_adverb\n",
        "frequency_adverb = frequency_adverb\n",
        "\n",
        "# Generating questions\n",
        "questions = generate_questions1(subject, verb, obj, prep, time_adverb, place_adverb, degree_adverb, manner_adverb, frequency_adverb)\n",
        "\n",
        "# Displaying generated questions\n",
        "for i, question in enumerate(questions, 1):\n",
        "    question = re.sub(\"[']\", \"\", question)\n",
        "    question = re.sub(\"[,]\", \"\", question)\n",
        "    question = re.sub(\"[[]\", \"\", question)\n",
        "    question = re.sub(\"[]]\", \"\", question)\n",
        "    question = re.sub(\"[)]\", \"\", question)\n",
        "    question = re.sub(\"[(]\", \"\", question)\n",
        "    print(f\"Question {i}: {question}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEn8Xa7bqnxR",
        "outputId": "01e289fc-5432-4260-c221-0ead6f4b1648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: Who ate an apple  yesterday    ?\n",
            "Question 2: What did John ate  yesterday    ?\n",
            "Question 3: When did John ate an apple     ?\n",
            "Question 4: Did John ate an apple  yesterday    ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatic Question Generation based on Extracted Information\n",
        "\n",
        "# Function to generate questions\n",
        "def generate_questions(subject, verb, obj, prep, time_adverb, place_adverb):\n",
        "    questions = []\n",
        "\n",
        "    # Generate Wh-questions\n",
        "    if subject:\n",
        "        questions.append(f\"Who {verb} {obj} {prep} {time_adverb} {place_adverb}?\")\n",
        "\n",
        "    if obj:\n",
        "        questions.append(f\"What did {subject} {verb} {prep} {time_adverb} {place_adverb}?\")\n",
        "\n",
        "    if time_adverb:\n",
        "        questions.append(f\"When did {subject} {verb} {obj} {prep} {place_adverb}?\")\n",
        "\n",
        "    if place_adverb:\n",
        "        questions.append(f\"Where did {subject} {verb} {obj} {prep} {time_adverb}?\")\n",
        "\n",
        "    # Generate Yes/No questions\n",
        "    if subject and verb and obj:\n",
        "        questions.append(f\"Did {subject} {verb} {obj}?\")\n",
        "\n",
        "    return questions\n",
        "\n",
        "# Using extracted information\n",
        "subject = nsubj\n",
        "verb = dobj\n",
        "obj = pobj\n",
        "prep = prep\n",
        "time_adverb = time_adverb\n",
        "place_adverb = place_adverb\n",
        "\n",
        "# Generating questions\n",
        "questions = generate_questions(subject, verb, obj, prep, time_adverb, place_adverb)\n",
        "\n",
        "# Displaying generated questions\n",
        "for i, question in enumerate(questions, 1):\n",
        "    question = re.sub(\"[']\", \"\", question)\n",
        "    question = re.sub(\"[,]\", \"\", question)\n",
        "    question = re.sub(\"[[]\", \"\", question)\n",
        "    question = re.sub(\"[]]\", \"\", question)\n",
        "    question = re.sub(\"[)]\", \"\", question)\n",
        "    question = re.sub(\"[(]\", \"\", question)\n",
        "    print(f\"Question {i}: {question}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXSusH1pqIJa",
        "outputId": "55dfce23-a219-47f6-f506-13efd92f082a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: Who ate an apple  yesterday ?\n",
            "Question 2: What did John ate  yesterday ?\n",
            "Question 3: When did John ate an apple  ?\n",
            "Question 4: Did John ate an apple?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GUI**"
      ],
      "metadata": {
        "id": "pJuvDJ2af2I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_questions(questions):\n",
        "  # Displaying generated questions\n",
        "  for i, question in enumerate(questions, 1):\n",
        "      question = re.sub(\"[']\", \"\", question)\n",
        "      question = re.sub(\"[,]\", \"\", question)\n",
        "      question = re.sub(\"[[]\", \"\", question)\n",
        "      question = re.sub(\"[]]\", \"\", question)\n",
        "      question = re.sub(\"[)]\", \"\", question)\n",
        "      question = re.sub(\"[(]\", \"\", question)\n",
        "      print(f\"Question {i}: {question}\")\n",
        "      return question"
      ],
      "metadata": {
        "id": "0_a3klhDkhwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example list of questions\n",
        "questions_list = [\"What's your name?\", \"How are you?\"]\n",
        "\n",
        "# Calling the function\n",
        "display_questions(questions_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "VSbj2jqmkwvK",
        "outputId": "8b33942c-b164-441f-8529-f9d1c8771d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1: Whats your name?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Whats your name?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "  return \"Hello \" + Input Text + \"!\"\n",
        "\n",
        "greet(\"World\")"
      ],
      "metadata": {
        "id": "AifbejO6f1cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "XoZU0gvPgOJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio\n",
        "\n",
        "gradio.Interface(greet, \"text\", \"text\").launch(share=True)"
      ],
      "metadata": {
        "id": "KO3m9xbtg4YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GUI**"
      ],
      "metadata": {
        "id": "QA0x054Dsgoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "S_k06YqCtDQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade typing_extensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuI7Lt9-dMBD",
        "outputId": "3eb44854-b6f4-4e42-8d94-e5332e4fe26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio"
      ],
      "metadata": {
        "id": "pWP4n3B1dOz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fastapi starlette"
      ],
      "metadata": {
        "id": "MRyA3JhQdelm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip check"
      ],
      "metadata": {
        "id": "3N55ZHD4diqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "c8T2sScbtf30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def process_text(text):\n",
        "    s = []\n",
        "    nsubj = []\n",
        "    dobj = []\n",
        "    pobj = []\n",
        "    prep = []\n",
        "    time_adverb = []\n",
        "    place_adverb = []\n",
        "    degree_adverb = []\n",
        "    manner_adverb = []\n",
        "    frequency_adverb = []\n",
        "\n",
        "    adverb_types = {\n",
        "        \"Degree\": [\"Somewhat\", \"Enormously\", \"Totally\", \"Utterly\", \"Perfectly\", \"Absolutely\", \"Practically\", \"Barely\",\n",
        "                   \"Terribly\", \"Pretty\", \"Thoroughly\", \"Rather\", \"Extremely\", \"Incredibly\", \"Most\", \"Purely\", \"Little\",\n",
        "                   \"Virtually\", \"Very\", \"Fully\", \"Indeed\", \"Hardly\", \"Almost\", \"Strongly\", \"So\", \"Less\", \"Fairly\",\n",
        "                   \"Greatly\", \"Entirely\", \"Highly\", \"Lots\", \"Really\", \"Quite\", \"Too\", \"Completely\", \"Well\", \"Far\",\n",
        "                   \"Deeply\", \"Badly\", \"Scarcely\", \"Positively\", \"How\", \"Enough\", \"Awfully\"],\n",
        "        \"Manner\": [\"Promptly\", \"Powerfully\", \"Calmly\", \"Politely\", \"Equally\", \"Faithfully\", \"Generously\", \"Gladly\",\n",
        "                   \"Joyously\", \"Easily\", \"Beautifully\", \"Kindly\", \"Bravely\", \"Poorly\", \"Shyly\", \"Foolishly\", \"Selfishly\",\n",
        "                   \"Angrily\", \"Awkwardly\", \"Violently\", \"Suspiciously\", \"Inadequately\", \"Irritably\", \"Hungrily\",\n",
        "                   \"Generally\", \"Frequently\", \"Noisily\"],\n",
        "        \"Place\": [\"Behind\", \"About\", \"Upstairs\", \"Up\", \"Out\", \"Far\", \"Inside\", \"Right\", \"There\", \"Backward/s\", \"Nearby\",\n",
        "                  \"On\", \"Away\", \"Back\", \"Indoors\", \"Overseas\", \"Abroad\", \"Down\", \"Over\", \"Towards\", \"Here\", \"Anywhere\",\n",
        "                  \"Underground\", \"Elsewhere\", \"Off\", \"Regularly\", \"Previously\", \"Seldom\", \"Now\", \"Since\", \"Finally\",\n",
        "                  \"Tomorrow\", \"Everywhere\"],\n",
        "        \"Time\": [\"Today\", \"Tonigh\", \"Occasionally\", \"Constantly\", \"Rarely\", \"Quarterly\", \"Weekly\", \"Yesterday\", \"Later\",\n",
        "                 \"Then\", \"Eventually\", \"Suddenly\", \"Mysteriously\", \"Infrequently\", \"Continually\", \"Yearly\", \"Monthly\",\n",
        "                 \"Fortnightly\", \"First\", \"Annually\", \"Yearly\", \"Tonight\", \"Tomorrow\", \"Recently\", \"Late\", \"Accidentally\",\n",
        "                 \"Seriouly\", \"Deliberately\", \"Never\", \"Seriously\", \"NaN\"],\n",
        "        \"Frequency\": [\"Exactly\", \"Intermittently\", \"Quarterly\", \"Weekly\", \"Solemnly\"]\n",
        "    }\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for token in doc:\n",
        "        s.append(token.text)\n",
        "        if token.dep_ == 'nsubj':\n",
        "            nsubj = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Subject type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ == 'ROOT':\n",
        "            dobj = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Verb type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ in ['pobj', 'dobj', 'acomp']:\n",
        "            pobj = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Object type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ == 'prep':\n",
        "            prep = s\n",
        "            s = []\n",
        "            subjNer = nlp(token.text)\n",
        "            for ent in subjNer.ents:\n",
        "                print(\"Preposition type=\", ent.label_, ent.text)\n",
        "\n",
        "        if token.dep_ == 'npadvmod':\n",
        "            npadvmod = s\n",
        "            s = []\n",
        "\n",
        "        if token.dep_ == 'advmod':\n",
        "            advmod = s\n",
        "            s = []\n",
        "\n",
        "    # Categorize adverbs based on adverb type dataset\n",
        "    adverb_type_category = \"\"\n",
        "    for adverb in advmod:\n",
        "        adverb = re.sub(\"[']\", \"\", adverb)\n",
        "        adverb = re.sub(\"[,]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[[]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[]]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[)]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[(]\", \"\", adverb)\n",
        "\n",
        "        if adverb in adverb_types[\"Degree\"]:\n",
        "            adverb_type_category = \"Degree\"\n",
        "            degree_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Manner\"]:\n",
        "            adverb_type_category = \"Manner\"\n",
        "            manner_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Place\"]:\n",
        "            adverb_type_category = \"Place\"\n",
        "            place_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Time\"]:\n",
        "            adverb_type_category = \"Time\"\n",
        "            time_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Frequency\"]:\n",
        "            adverb_type_category = \"Frequency\"\n",
        "            frequency_adverb.append(adverb)\n",
        "\n",
        "    for adverb in npadvmod:\n",
        "        adverb = re.sub(\"[']\", \"\", adverb)\n",
        "        adverb = re.sub(\"[,]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[[]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[]]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[)]\", \"\", adverb)\n",
        "        adverb = re.sub(\"[(]\", \"\", adverb)\n",
        "\n",
        "        if adverb in adverb_types[\"Degree\"]:\n",
        "            adverb_type_category = \"Degree\"\n",
        "            degree_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Manner\"]:\n",
        "            adverb_type_category = \"Manner\"\n",
        "            manner_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Place\"]:\n",
        "            adverb_type_category = \"Place\"\n",
        "            place_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Time\"]:\n",
        "            adverb_type_category = \"Time\"\n",
        "            time_adverb.append(adverb)\n",
        "        elif adverb in adverb_types[\"Frequency\"]:\n",
        "            adverb_type_category = \"Frequency\"\n",
        "            frequency_adverb.append(adverb)\n",
        "\n",
        "    # Generating questions\n",
        "    questions = []\n",
        "\n",
        "    # Function to generate questions\n",
        "    def generate_questions(subject, verb, obj, prep, time_adverb, place_adverb, degree_adverb, manner_adverb,\n",
        "                           frequency_adverb):\n",
        "        generated_questions = []\n",
        "\n",
        "        # Generate Wh-questions\n",
        "        if subject:\n",
        "            generated_questions.append(\n",
        "                f\"Who {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "        if obj:\n",
        "            generated_questions.append(\n",
        "                f\"What did {subject} {verb} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "        if time_adverb:\n",
        "            generated_questions.append(\n",
        "                f\"When did {subject} {verb} {obj} {prep} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "        if place_adverb:\n",
        "            generated_questions.append(\n",
        "                f\"Where did {subject} {verb} {obj} {prep} {time_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "        if degree_adverb:\n",
        "            generated_questions.append(\n",
        "                f\"How {degree_adverb[0]} did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "        if manner_adverb:\n",
        "            generated_questions.append(\n",
        "                f\"How did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {frequency_adverb}?\")\n",
        "\n",
        "        if frequency_adverb:\n",
        "            generated_questions.append(\n",
        "                f\"How often did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb}?\")\n",
        "\n",
        "        # Generate Yes/No questions\n",
        "        if subject and verb and obj:\n",
        "            generated_questions.append(\n",
        "                f\"Did {subject} {verb} {obj} {prep} {time_adverb} {place_adverb} {degree_adverb} {manner_adverb} {frequency_adverb}?\")\n",
        "\n",
        "        return generated_questions\n",
        "\n",
        "    # Using extracted information\n",
        "    subject = nsubj\n",
        "    verb = dobj\n",
        "    obj = pobj\n",
        "    prep = prep\n",
        "    time_adverb = time_adverb\n",
        "    place_adverb = place_adverb\n",
        "    degree_adverb = degree_adverb\n",
        "    manner_adverb = manner_adverb\n",
        "    frequency_adverb = frequency_adverb\n",
        "\n",
        "    # Generating questions\n",
        "    questions = generate_questions(subject, verb, obj, prep, time_adverb, place_adverb, degree_adverb, manner_adverb,\n",
        "                                   frequency_adverb)\n",
        "\n",
        "    return {\"input_text\": text, \"questions\": questions}\n",
        "\n",
        "\n",
        "iface = gr.Interface(fn=process_text, inputs=\"text\", outputs=[\"text\", \"text\"])\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "AmgZ1tGxsizB",
        "outputId": "840f71ea-d47f-404c-eebd-748587cfc9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a17a29ef5dc3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_templates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/_simple_templates/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpledropdown\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleDropdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpletextbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleTextbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SimpleDropdown\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SimpleTextbox\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/_simple_templates/simpledropdown.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormComponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/components/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotated_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotatedImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_plot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBarPlot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from gradio.components.base import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mComponent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/components/annotated_image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_Image\u001b[0m  \u001b[0;31m# using _ to minimize namespace pollution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocessing_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwasm_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioRootModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/data_classes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastapi/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstarlette\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastAPI\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackground\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackgroundTasks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mBackgroundTasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatastructures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUploadFile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mUploadFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrouting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatastructures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDefaultPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m from fastapi.exception_handlers import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m from fastapi._compat import (\n\u001b[1;32m     24\u001b[0m     \u001b[0mModelField\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastapi/params.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFieldInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastapi/openapi/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from fastapi._compat import (\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mPYDANTIC_V2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mCoreSchema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastapi/_compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequestErrorModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIncEx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelNameMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnionType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastapi/exceptions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstarlette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mStarletteHTTPException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstarlette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebSocketException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mStarletteWebSocketException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoc\u001b[0m  \u001b[0;31m# type: ignore [attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Doc' from 'typing_extensions' (/usr/local/lib/python3.10/dist-packages/typing_extensions.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}